# 信息理论

## 课程学习内容

信息论是以前信工的必修，现在变成了工高的课。

信息论是服务于通信的应用数学，将生活中的信息载体（如文字）建模成随机变量序列，以此和概率论挂钩。然后，用概率作为工具解决几个问题：

1.如何高效地编码。输入一个随机变量序列，需要多少bit才能做到几乎无差错地表示。(几乎指的是当序列长度趋向于正无穷时，出错的概率趋于0）.这个理论下限对应香农第一定理。
2.如何高效地传输。对一个有噪声的信道，我们需要更多的比特才能完成几乎无差错的传输。严谨地说，给定一个输入序列和一个有噪声信道，我要找到一个编码器和一译码器，使得编码尽可能地短，换句话说，一个bit承载尽可能多的信息（输入序列：X1X2...其中Xn属于{a,b,c,d...}；信道：发送端发送的一个bit，比如1，有概率p变成0。抽象地说，信道就是一个条件概率矩阵，表示给定输入比特后，输出比特的概率分布；编码器：输入字符a到比特码001的映射；译码器：比特码到字符a的映射。由于这里比特码的种数往往大于输入字符，这常常不是单射，这点冗余可以对抗噪声）。这个理论上限对应香农第二定理。
3.如何高效地有损压缩。给定一个误差D和一个失真度量函数d（类似距离函数，用来衡量压缩得到的y相对于输入的x的偏离程度），要找出一对编码译码器，使在误差期望小于D的前提下，编码尽可能地短。比如，将形如3.14...的小数都编码成010101，然后译码器把所有010101都译为3.14，总体的效应就是3.14...被截断存储为3.14，即对输入序列集合进行划分，每个划分选出一个代表元作为近似。

### 先修要求

学过数分I的同学都能学。名义上是高级概率论，实际上几乎仅用到了概率论中的切比雪夫不等式，以及高中概率论，这些不需要提前准备。另外，极限思想对理解当输入序列长度充分大时，他们几乎都是典型列（一种特殊的输入序列）有帮助。

## 任课教师

=== "余官定"

    余老师上课清晰且幽默，强调物理意义帮助理解，对于工科生十分友好。同时余老师也会根据工科同学的需要进行拓展和删减，25年也有一节课由余老师博士生讲解信息瓶颈理论，信息论在ML中的一个应用。


## 课程教材

***信息论与编码*  仇佩亮**
比较清晰易懂，适当时会用文字和图表帮助理解。内容同PPT。


